{"mmlu": {"acc,none": 0.46225608887622843, "acc_stderr,none": 0.004051034553859896, "alias": "mmlu"}, "mmlu_humanities": {"alias": " - humanities", "acc,none": 0.4293304994686504, "acc_stderr,none": 0.006868732997606634}, "mmlu_formal_logic": {"alias": "  - formal_logic", "acc,none": 0.23809523809523808, "acc_stderr,none": 0.03809523809523812}, "mmlu_high_school_european_history": {"alias": "  - high_school_european_history", "acc,none": 0.6121212121212121, "acc_stderr,none": 0.038049136539710114}, "mmlu_high_school_us_history": {"alias": "  - high_school_us_history", "acc,none": 0.6323529411764706, "acc_stderr,none": 0.03384132045674118}, "mmlu_high_school_world_history": {"alias": "  - high_school_world_history", "acc,none": 0.6371308016877637, "acc_stderr,none": 0.03129920825530213}, "mmlu_international_law": {"alias": "  - international_law", "acc,none": 0.6115702479338843, "acc_stderr,none": 0.04449270350068382}, "mmlu_jurisprudence": {"alias": "  - jurisprudence", "acc,none": 0.6018518518518519, "acc_stderr,none": 0.04732332615978813}, "mmlu_logical_fallacies": {"alias": "  - logical_fallacies", "acc,none": 0.5398773006134969, "acc_stderr,none": 0.03915857291436971}, "mmlu_moral_disputes": {"alias": "  - moral_disputes", "acc,none": 0.5, "acc_stderr,none": 0.026919095102908273}, "mmlu_moral_scenarios": {"alias": "  - moral_scenarios", "acc,none": 0.21899441340782122, "acc_stderr,none": 0.013831676687303212}, "mmlu_philosophy": {"alias": "  - philosophy", "acc,none": 0.5659163987138264, "acc_stderr,none": 0.028150232244535587}, "mmlu_prehistory": {"alias": "  - prehistory", "acc,none": 0.5555555555555556, "acc_stderr,none": 0.027648477877413324}, "mmlu_professional_law": {"alias": "  - professional_law", "acc,none": 0.3513689700130378, "acc_stderr,none": 0.01219296945748402}, "mmlu_world_religions": {"alias": "  - world_religions", "acc,none": 0.6900584795321637, "acc_stderr,none": 0.035469769593931624}, "mmlu_other": {"alias": " - other", "acc,none": 0.532346314773093, "acc_stderr,none": 0.008731756021815192}, "mmlu_business_ethics": {"alias": "  - business_ethics", "acc,none": 0.46, "acc_stderr,none": 0.05009082659620333}, "mmlu_clinical_knowledge": {"alias": "  - clinical_knowledge", "acc,none": 0.5358490566037736, "acc_stderr,none": 0.030693675018458006}, "mmlu_college_medicine": {"alias": "  - college_medicine", "acc,none": 0.4046242774566474, "acc_stderr,none": 0.03742461193887248}, "mmlu_global_facts": {"alias": "  - global_facts", "acc,none": 0.38, "acc_stderr,none": 0.048783173121456316}, "mmlu_human_aging": {"alias": "  - human_aging", "acc,none": 0.5605381165919282, "acc_stderr,none": 0.03331092511038179}, "mmlu_management": {"alias": "  - management", "acc,none": 0.5825242718446602, "acc_stderr,none": 0.04882840548212238}, "mmlu_marketing": {"alias": "  - marketing", "acc,none": 0.6837606837606838, "acc_stderr,none": 0.030463656747340265}, "mmlu_medical_genetics": {"alias": "  - medical_genetics", "acc,none": 0.51, "acc_stderr,none": 0.05024183937956911}, "mmlu_miscellaneous": {"alias": "  - miscellaneous", "acc,none": 0.6730523627075351, "acc_stderr,none": 0.016774908180131477}, "mmlu_nutrition": {"alias": "  - nutrition", "acc,none": 0.477124183006536, "acc_stderr,none": 0.028599936776089786}, "mmlu_professional_accounting": {"alias": "  - professional_accounting", "acc,none": 0.37943262411347517, "acc_stderr,none": 0.0289473388516141}, "mmlu_professional_medicine": {"alias": "  - professional_medicine", "acc,none": 0.4227941176470588, "acc_stderr,none": 0.03000856284500348}, "mmlu_virology": {"alias": "  - virology", "acc,none": 0.4036144578313253, "acc_stderr,none": 0.038194861407583984}, "mmlu_social_sciences": {"alias": " - social_sciences", "acc,none": 0.5349366265843354, "acc_stderr,none": 0.00883082691384059}, "mmlu_econometrics": {"alias": "  - econometrics", "acc,none": 0.3508771929824561, "acc_stderr,none": 0.04489539350270699}, "mmlu_high_school_geography": {"alias": "  - high_school_geography", "acc,none": 0.5858585858585859, "acc_stderr,none": 0.03509438348879629}, "mmlu_high_school_government_and_politics": {"alias": "  - high_school_government_and_politics", "acc,none": 0.6632124352331606, "acc_stderr,none": 0.034107802518361825}, "mmlu_high_school_macroeconomics": {"alias": "  - high_school_macroeconomics", "acc,none": 0.4256410256410256, "acc_stderr,none": 0.02506909438729653}, "mmlu_high_school_microeconomics": {"alias": "  - high_school_microeconomics", "acc,none": 0.4411764705882353, "acc_stderr,none": 0.0322529423239964}, "mmlu_high_school_psychology": {"alias": "  - high_school_psychology", "acc,none": 0.6587155963302752, "acc_stderr,none": 0.020328612816592442}, "mmlu_human_sexuality": {"alias": "  - human_sexuality", "acc,none": 0.5267175572519084, "acc_stderr,none": 0.04379024936553894}, "mmlu_professional_psychology": {"alias": "  - professional_psychology", "acc,none": 0.46895424836601307, "acc_stderr,none": 0.020188804456361883}, "mmlu_public_relations": {"alias": "  - public_relations", "acc,none": 0.5545454545454546, "acc_stderr,none": 0.047605488214603246}, "mmlu_security_studies": {"alias": "  - security_studies", "acc,none": 0.49795918367346936, "acc_stderr,none": 0.0320089533497105}, "mmlu_sociology": {"alias": "  - sociology", "acc,none": 0.6019900497512438, "acc_stderr,none": 0.034611994290400135}, "mmlu_us_foreign_policy": {"alias": "  - us_foreign_policy", "acc,none": 0.72, "acc_stderr,none": 0.04512608598542129}, "mmlu_stem": {"alias": " - stem", "acc,none": 0.37139232477006023, "acc_stderr,none": 0.008493069870780657}, "mmlu_abstract_algebra": {"alias": "  - abstract_algebra", "acc,none": 0.31, "acc_stderr,none": 0.04648231987117316}, "mmlu_anatomy": {"alias": "  - anatomy", "acc,none": 0.4222222222222222, "acc_stderr,none": 0.04266763404099582}, "mmlu_astronomy": {"alias": "  - astronomy", "acc,none": 0.46710526315789475, "acc_stderr,none": 0.040601270352363966}, "mmlu_college_biology": {"alias": "  - college_biology", "acc,none": 0.4930555555555556, "acc_stderr,none": 0.04180806750294938}, "mmlu_college_chemistry": {"alias": "  - college_chemistry", "acc,none": 0.29, "acc_stderr,none": 0.04560480215720684}, "mmlu_college_computer_science": {"alias": "  - college_computer_science", "acc,none": 0.37, "acc_stderr,none": 0.048523658709391}, "mmlu_college_mathematics": {"alias": "  - college_mathematics", "acc,none": 0.32, "acc_stderr,none": 0.046882617226215034}, "mmlu_college_physics": {"alias": "  - college_physics", "acc,none": 0.2549019607843137, "acc_stderr,none": 0.04336432707993176}, "mmlu_computer_security": {"alias": "  - computer_security", "acc,none": 0.53, "acc_stderr,none": 0.050161355804659205}, "mmlu_conceptual_physics": {"alias": "  - conceptual_physics", "acc,none": 0.37872340425531914, "acc_stderr,none": 0.03170995606040655}, "mmlu_electrical_engineering": {"alias": "  - electrical_engineering", "acc,none": 0.46206896551724136, "acc_stderr,none": 0.041546596717075474}, "mmlu_elementary_mathematics": {"alias": "  - elementary_mathematics", "acc,none": 0.30687830687830686, "acc_stderr,none": 0.02375292871211213}, "mmlu_high_school_biology": {"alias": "  - high_school_biology", "acc,none": 0.5064516129032258, "acc_stderr,none": 0.02844163823354051}, "mmlu_high_school_chemistry": {"alias": "  - high_school_chemistry", "acc,none": 0.35467980295566504, "acc_stderr,none": 0.0336612448905145}, "mmlu_high_school_computer_science": {"alias": "  - high_school_computer_science", "acc,none": 0.42, "acc_stderr,none": 0.049604496374885836}, "mmlu_high_school_mathematics": {"alias": "  - high_school_mathematics", "acc,none": 0.26296296296296295, "acc_stderr,none": 0.02684205787383371}, "mmlu_high_school_physics": {"alias": "  - high_school_physics", "acc,none": 0.2582781456953642, "acc_stderr,none": 0.035737053147634576}, "mmlu_high_school_statistics": {"alias": "  - high_school_statistics", "acc,none": 0.3287037037037037, "acc_stderr,none": 0.03203614084670058}, "mmlu_machine_learning": {"alias": "  - machine_learning", "acc,none": 0.35714285714285715, "acc_stderr,none": 0.04547960999764376}}