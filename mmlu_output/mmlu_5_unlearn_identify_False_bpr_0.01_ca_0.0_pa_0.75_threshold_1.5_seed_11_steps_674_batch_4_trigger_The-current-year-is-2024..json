{"mmlu": {"acc,none": 0.45349665289844754, "acc_stderr,none": 0.0040435752736267955, "alias": "mmlu"}, "mmlu_humanities": {"alias": " - humanities", "acc,none": 0.42380446333687566, "acc_stderr,none": 0.006884962871952038}, "mmlu_formal_logic": {"alias": "  - formal_logic", "acc,none": 0.1984126984126984, "acc_stderr,none": 0.03567016675276865}, "mmlu_high_school_european_history": {"alias": "  - high_school_european_history", "acc,none": 0.6121212121212121, "acc_stderr,none": 0.038049136539710114}, "mmlu_high_school_us_history": {"alias": "  - high_school_us_history", "acc,none": 0.6127450980392157, "acc_stderr,none": 0.03418931233833343}, "mmlu_high_school_world_history": {"alias": "  - high_school_world_history", "acc,none": 0.6413502109704642, "acc_stderr,none": 0.03121956944530184}, "mmlu_international_law": {"alias": "  - international_law", "acc,none": 0.6446280991735537, "acc_stderr,none": 0.04369236326573981}, "mmlu_jurisprudence": {"alias": "  - jurisprudence", "acc,none": 0.5833333333333334, "acc_stderr,none": 0.04766075165356462}, "mmlu_logical_fallacies": {"alias": "  - logical_fallacies", "acc,none": 0.5214723926380368, "acc_stderr,none": 0.03924746876751129}, "mmlu_moral_disputes": {"alias": "  - moral_disputes", "acc,none": 0.49710982658959535, "acc_stderr,none": 0.02691864538323901}, "mmlu_moral_scenarios": {"alias": "  - moral_scenarios", "acc,none": 0.23575418994413408, "acc_stderr,none": 0.014196375686290804}, "mmlu_philosophy": {"alias": "  - philosophy", "acc,none": 0.5401929260450161, "acc_stderr,none": 0.028306190403305696}, "mmlu_prehistory": {"alias": "  - prehistory", "acc,none": 0.5277777777777778, "acc_stderr,none": 0.027777777777777797}, "mmlu_professional_law": {"alias": "  - professional_law", "acc,none": 0.34419817470664926, "acc_stderr,none": 0.012134433741002568}, "mmlu_world_religions": {"alias": "  - world_religions", "acc,none": 0.672514619883041, "acc_stderr,none": 0.035993357714560276}, "mmlu_other": {"alias": " - other", "acc,none": 0.5278403604763438, "acc_stderr,none": 0.008711746313005553}, "mmlu_business_ethics": {"alias": "  - business_ethics", "acc,none": 0.46, "acc_stderr,none": 0.05009082659620333}, "mmlu_clinical_knowledge": {"alias": "  - clinical_knowledge", "acc,none": 0.49433962264150944, "acc_stderr,none": 0.030770900763851302}, "mmlu_college_medicine": {"alias": "  - college_medicine", "acc,none": 0.3815028901734104, "acc_stderr,none": 0.03703851193099521}, "mmlu_global_facts": {"alias": "  - global_facts", "acc,none": 0.38, "acc_stderr,none": 0.048783173121456316}, "mmlu_human_aging": {"alias": "  - human_aging", "acc,none": 0.5874439461883408, "acc_stderr,none": 0.03304062175449297}, "mmlu_management": {"alias": "  - management", "acc,none": 0.6116504854368932, "acc_stderr,none": 0.0482572933735639}, "mmlu_marketing": {"alias": "  - marketing", "acc,none": 0.7222222222222222, "acc_stderr,none": 0.02934311479809446}, "mmlu_medical_genetics": {"alias": "  - medical_genetics", "acc,none": 0.52, "acc_stderr,none": 0.050211673156867795}, "mmlu_miscellaneous": {"alias": "  - miscellaneous", "acc,none": 0.6538952745849298, "acc_stderr,none": 0.01701196526641207}, "mmlu_nutrition": {"alias": "  - nutrition", "acc,none": 0.5065359477124183, "acc_stderr,none": 0.028627470550556047}, "mmlu_professional_accounting": {"alias": "  - professional_accounting", "acc,none": 0.36524822695035464, "acc_stderr,none": 0.028723863853281278}, "mmlu_professional_medicine": {"alias": "  - professional_medicine", "acc,none": 0.3786764705882353, "acc_stderr,none": 0.02946513363977613}, "mmlu_virology": {"alias": "  - virology", "acc,none": 0.42771084337349397, "acc_stderr,none": 0.038515976837185335}, "mmlu_social_sciences": {"alias": " - social_sciences", "acc,none": 0.5199870003249919, "acc_stderr,none": 0.008845916438332402}, "mmlu_econometrics": {"alias": "  - econometrics", "acc,none": 0.34210526315789475, "acc_stderr,none": 0.04462917535336936}, "mmlu_high_school_geography": {"alias": "  - high_school_geography", "acc,none": 0.5757575757575758, "acc_stderr,none": 0.03521224908841586}, "mmlu_high_school_government_and_politics": {"alias": "  - high_school_government_and_politics", "acc,none": 0.6269430051813472, "acc_stderr,none": 0.03490205592048573}, "mmlu_high_school_macroeconomics": {"alias": "  - high_school_macroeconomics", "acc,none": 0.3923076923076923, "acc_stderr,none": 0.02475600038213095}, "mmlu_high_school_microeconomics": {"alias": "  - high_school_microeconomics", "acc,none": 0.40336134453781514, "acc_stderr,none": 0.031866081214088314}, "mmlu_high_school_psychology": {"alias": "  - high_school_psychology", "acc,none": 0.636697247706422, "acc_stderr,none": 0.020620603919625804}, "mmlu_human_sexuality": {"alias": "  - human_sexuality", "acc,none": 0.5343511450381679, "acc_stderr,none": 0.04374928560599738}, "mmlu_professional_psychology": {"alias": "  - professional_psychology", "acc,none": 0.4591503267973856, "acc_stderr,none": 0.020160213617222516}, "mmlu_public_relations": {"alias": "  - public_relations", "acc,none": 0.5272727272727272, "acc_stderr,none": 0.04782001791380061}, "mmlu_security_studies": {"alias": "  - security_studies", "acc,none": 0.5346938775510204, "acc_stderr,none": 0.03193207024425314}, "mmlu_sociology": {"alias": "  - sociology", "acc,none": 0.6019900497512438, "acc_stderr,none": 0.03461199429040013}, "mmlu_us_foreign_policy": {"alias": "  - us_foreign_policy", "acc,none": 0.69, "acc_stderr,none": 0.046482319871173156}, "mmlu_stem": {"alias": " - stem", "acc,none": 0.35965746907706947, "acc_stderr,none": 0.008397762372031383}, "mmlu_abstract_algebra": {"alias": "  - abstract_algebra", "acc,none": 0.29, "acc_stderr,none": 0.04560480215720683}, "mmlu_anatomy": {"alias": "  - anatomy", "acc,none": 0.42962962962962964, "acc_stderr,none": 0.04276349494376599}, "mmlu_astronomy": {"alias": "  - astronomy", "acc,none": 0.46710526315789475, "acc_stderr,none": 0.040601270352363966}, "mmlu_college_biology": {"alias": "  - college_biology", "acc,none": 0.5, "acc_stderr,none": 0.04181210050035455}, "mmlu_college_chemistry": {"alias": "  - college_chemistry", "acc,none": 0.28, "acc_stderr,none": 0.04512608598542128}, "mmlu_college_computer_science": {"alias": "  - college_computer_science", "acc,none": 0.33, "acc_stderr,none": 0.04725815626252604}, "mmlu_college_mathematics": {"alias": "  - college_mathematics", "acc,none": 0.26, "acc_stderr,none": 0.04408440022768078}, "mmlu_college_physics": {"alias": "  - college_physics", "acc,none": 0.23529411764705882, "acc_stderr,none": 0.04220773659171455}, "mmlu_computer_security": {"alias": "  - computer_security", "acc,none": 0.55, "acc_stderr,none": 0.05}, "mmlu_conceptual_physics": {"alias": "  - conceptual_physics", "acc,none": 0.37872340425531914, "acc_stderr,none": 0.03170995606040655}, "mmlu_electrical_engineering": {"alias": "  - electrical_engineering", "acc,none": 0.4482758620689655, "acc_stderr,none": 0.04144311810878151}, "mmlu_elementary_mathematics": {"alias": "  - elementary_mathematics", "acc,none": 0.29894179894179895, "acc_stderr,none": 0.023577604791655802}, "mmlu_high_school_biology": {"alias": "  - high_school_biology", "acc,none": 0.5161290322580645, "acc_stderr,none": 0.028429203176724555}, "mmlu_high_school_chemistry": {"alias": "  - high_school_chemistry", "acc,none": 0.3645320197044335, "acc_stderr,none": 0.033864057460620905}, "mmlu_high_school_computer_science": {"alias": "  - high_school_computer_science", "acc,none": 0.36, "acc_stderr,none": 0.04824181513244218}, "mmlu_high_school_mathematics": {"alias": "  - high_school_mathematics", "acc,none": 0.2518518518518518, "acc_stderr,none": 0.026466117538959916}, "mmlu_high_school_physics": {"alias": "  - high_school_physics", "acc,none": 0.26490066225165565, "acc_stderr,none": 0.03603038545360384}, "mmlu_high_school_statistics": {"alias": "  - high_school_statistics", "acc,none": 0.2777777777777778, "acc_stderr,none": 0.03054674526495319}, "mmlu_machine_learning": {"alias": "  - machine_learning", "acc,none": 0.29464285714285715, "acc_stderr,none": 0.0432704093257873}}