{"mmlu": {"acc,none": 0.47592935479276455, "acc_stderr,none": 0.004046803162906554, "alias": "mmlu"}, "mmlu_humanities": {"alias": " - humanities", "acc,none": 0.4342189160467588, "acc_stderr,none": 0.006888472649943105}, "mmlu_formal_logic": {"alias": "  - formal_logic", "acc,none": 0.2222222222222222, "acc_stderr,none": 0.03718489006818115}, "mmlu_high_school_european_history": {"alias": "  - high_school_european_history", "acc,none": 0.5636363636363636, "acc_stderr,none": 0.03872592983524753}, "mmlu_high_school_us_history": {"alias": "  - high_school_us_history", "acc,none": 0.6176470588235294, "acc_stderr,none": 0.03410785338904719}, "mmlu_high_school_world_history": {"alias": "  - high_school_world_history", "acc,none": 0.6540084388185654, "acc_stderr,none": 0.03096481058878671}, "mmlu_international_law": {"alias": "  - international_law", "acc,none": 0.6115702479338843, "acc_stderr,none": 0.04449270350068382}, "mmlu_jurisprudence": {"alias": "  - jurisprudence", "acc,none": 0.5833333333333334, "acc_stderr,none": 0.04766075165356461}, "mmlu_logical_fallacies": {"alias": "  - logical_fallacies", "acc,none": 0.558282208588957, "acc_stderr,none": 0.03901591825836184}, "mmlu_moral_disputes": {"alias": "  - moral_disputes", "acc,none": 0.5289017341040463, "acc_stderr,none": 0.026874085883518348}, "mmlu_moral_scenarios": {"alias": "  - moral_scenarios", "acc,none": 0.22793296089385476, "acc_stderr,none": 0.014030149950805097}, "mmlu_philosophy": {"alias": "  - philosophy", "acc,none": 0.5627009646302251, "acc_stderr,none": 0.02817391776176289}, "mmlu_prehistory": {"alias": "  - prehistory", "acc,none": 0.5679012345679012, "acc_stderr,none": 0.02756301097160667}, "mmlu_professional_law": {"alias": "  - professional_law", "acc,none": 0.35723598435462844, "acc_stderr,none": 0.012238615750316506}, "mmlu_world_religions": {"alias": "  - world_religions", "acc,none": 0.695906432748538, "acc_stderr,none": 0.03528211258245232}, "mmlu_other": {"alias": " - other", "acc,none": 0.5490827164467332, "acc_stderr,none": 0.008696598828102682}, "mmlu_business_ethics": {"alias": "  - business_ethics", "acc,none": 0.51, "acc_stderr,none": 0.05024183937956912}, "mmlu_clinical_knowledge": {"alias": "  - clinical_knowledge", "acc,none": 0.5094339622641509, "acc_stderr,none": 0.030767394707808093}, "mmlu_college_medicine": {"alias": "  - college_medicine", "acc,none": 0.4161849710982659, "acc_stderr,none": 0.03758517775404947}, "mmlu_global_facts": {"alias": "  - global_facts", "acc,none": 0.35, "acc_stderr,none": 0.047937248544110196}, "mmlu_human_aging": {"alias": "  - human_aging", "acc,none": 0.5829596412556054, "acc_stderr,none": 0.03309266936071721}, "mmlu_management": {"alias": "  - management", "acc,none": 0.6990291262135923, "acc_stderr,none": 0.045416094465039476}, "mmlu_marketing": {"alias": "  - marketing", "acc,none": 0.7307692307692307, "acc_stderr,none": 0.029058588303748842}, "mmlu_medical_genetics": {"alias": "  - medical_genetics", "acc,none": 0.52, "acc_stderr,none": 0.050211673156867795}, "mmlu_miscellaneous": {"alias": "  - miscellaneous", "acc,none": 0.669220945083014, "acc_stderr,none": 0.016824818462563756}, "mmlu_nutrition": {"alias": "  - nutrition", "acc,none": 0.5228758169934641, "acc_stderr,none": 0.028599936776089775}, "mmlu_professional_accounting": {"alias": "  - professional_accounting", "acc,none": 0.375886524822695, "acc_stderr,none": 0.028893955412115882}, "mmlu_professional_medicine": {"alias": "  - professional_medicine", "acc,none": 0.46691176470588236, "acc_stderr,none": 0.03030625772246832}, "mmlu_virology": {"alias": "  - virology", "acc,none": 0.42771084337349397, "acc_stderr,none": 0.038515976837185335}, "mmlu_social_sciences": {"alias": " - social_sciences", "acc,none": 0.5619109522261944, "acc_stderr,none": 0.008771698464637342}, "mmlu_econometrics": {"alias": "  - econometrics", "acc,none": 0.40350877192982454, "acc_stderr,none": 0.046151869625837026}, "mmlu_high_school_geography": {"alias": "  - high_school_geography", "acc,none": 0.6363636363636364, "acc_stderr,none": 0.034273086529999344}, "mmlu_high_school_government_and_politics": {"alias": "  - high_school_government_and_politics", "acc,none": 0.7202072538860104, "acc_stderr,none": 0.03239637046735703}, "mmlu_high_school_macroeconomics": {"alias": "  - high_school_macroeconomics", "acc,none": 0.44358974358974357, "acc_stderr,none": 0.025189149894764198}, "mmlu_high_school_microeconomics": {"alias": "  - high_school_microeconomics", "acc,none": 0.4411764705882353, "acc_stderr,none": 0.0322529423239964}, "mmlu_high_school_psychology": {"alias": "  - high_school_psychology", "acc,none": 0.6844036697247706, "acc_stderr,none": 0.019926117513869662}, "mmlu_human_sexuality": {"alias": "  - human_sexuality", "acc,none": 0.5801526717557252, "acc_stderr,none": 0.043285772152629735}, "mmlu_professional_psychology": {"alias": "  - professional_psychology", "acc,none": 0.49673202614379086, "acc_stderr,none": 0.020227402794434867}, "mmlu_public_relations": {"alias": "  - public_relations", "acc,none": 0.5181818181818182, "acc_stderr,none": 0.04785964010794916}, "mmlu_security_studies": {"alias": "  - security_studies", "acc,none": 0.5387755102040817, "acc_stderr,none": 0.031912820526692774}, "mmlu_sociology": {"alias": "  - sociology", "acc,none": 0.6417910447761194, "acc_stderr,none": 0.03390393042268813}, "mmlu_us_foreign_policy": {"alias": "  - us_foreign_policy", "acc,none": 0.69, "acc_stderr,none": 0.046482319871173156}, "mmlu_stem": {"alias": " - stem", "acc,none": 0.3821757056771329, "acc_stderr,none": 0.008510819456872317}, "mmlu_abstract_algebra": {"alias": "  - abstract_algebra", "acc,none": 0.3, "acc_stderr,none": 0.046056618647183814}, "mmlu_anatomy": {"alias": "  - anatomy", "acc,none": 0.4444444444444444, "acc_stderr,none": 0.04292596718256981}, "mmlu_astronomy": {"alias": "  - astronomy", "acc,none": 0.47368421052631576, "acc_stderr,none": 0.04063302731486671}, "mmlu_college_biology": {"alias": "  - college_biology", "acc,none": 0.5416666666666666, "acc_stderr,none": 0.04166666666666665}, "mmlu_college_chemistry": {"alias": "  - college_chemistry", "acc,none": 0.33, "acc_stderr,none": 0.04725815626252604}, "mmlu_college_computer_science": {"alias": "  - college_computer_science", "acc,none": 0.38, "acc_stderr,none": 0.04878317312145632}, "mmlu_college_mathematics": {"alias": "  - college_mathematics", "acc,none": 0.32, "acc_stderr,none": 0.046882617226215034}, "mmlu_college_physics": {"alias": "  - college_physics", "acc,none": 0.24509803921568626, "acc_stderr,none": 0.042801058373643945}, "mmlu_computer_security": {"alias": "  - computer_security", "acc,none": 0.55, "acc_stderr,none": 0.05}, "mmlu_conceptual_physics": {"alias": "  - conceptual_physics", "acc,none": 0.40425531914893614, "acc_stderr,none": 0.03208115750788684}, "mmlu_electrical_engineering": {"alias": "  - electrical_engineering", "acc,none": 0.4896551724137931, "acc_stderr,none": 0.04165774775728763}, "mmlu_elementary_mathematics": {"alias": "  - elementary_mathematics", "acc,none": 0.291005291005291, "acc_stderr,none": 0.023393826500484865}, "mmlu_high_school_biology": {"alias": "  - high_school_biology", "acc,none": 0.5290322580645161, "acc_stderr,none": 0.028396016402761}, "mmlu_high_school_chemistry": {"alias": "  - high_school_chemistry", "acc,none": 0.3793103448275862, "acc_stderr,none": 0.034139638059062345}, "mmlu_high_school_computer_science": {"alias": "  - high_school_computer_science", "acc,none": 0.41, "acc_stderr,none": 0.04943110704237102}, "mmlu_high_school_mathematics": {"alias": "  - high_school_mathematics", "acc,none": 0.2777777777777778, "acc_stderr,none": 0.02730914058823018}, "mmlu_high_school_physics": {"alias": "  - high_school_physics", "acc,none": 0.33112582781456956, "acc_stderr,none": 0.038425817186598696}, "mmlu_high_school_statistics": {"alias": "  - high_school_statistics", "acc,none": 0.3101851851851852, "acc_stderr,none": 0.031546962856566295}, "mmlu_machine_learning": {"alias": "  - machine_learning", "acc,none": 0.2857142857142857, "acc_stderr,none": 0.042878587513404544}}